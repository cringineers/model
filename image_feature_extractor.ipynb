{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import pyheif\n",
    "import rawpy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "\n",
    "df = pd.read_excel('dataset/razm.xlsx')\n",
    "files = ('dataset/images/' + df['Названия']).values\n",
    "batches = np.array_split(files, math.ceil(len(files) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    # Try to read image using PIL\n",
    "    try:\n",
    "        return Image.open(path)\n",
    "    except Image.UnidentifiedImageError:\n",
    "        pass\n",
    "    \n",
    "    # Try to read image using rawpy\n",
    "    try:\n",
    "        return Image.fromarray(rawpy.imread(path).postprocess())\n",
    "    except rawpy.LibRawFileUnsupportedError:\n",
    "        pass\n",
    "\n",
    "    # Try to read image using heif\n",
    "    try:\n",
    "        heif = pyheif.read_heif(path)\n",
    "        return Image.frombytes(mode=heif.mode, size=heif.size, data=heif.data)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/906 [00:08<08:49,  1.68it/s]"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(batches):\n",
    "        batch = torch.stack([preprocess(load_image(file)) for file in batch]).to(device)\n",
    "        features = model.encode_image(batch)\n",
    "        features /= features.norm(dim=-1, keepdim=True)\n",
    "        total.append(features)\n",
    "\n",
    "total = torch.cat(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(total, 'ViT-B-32-image-features.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ae789462ef566e12131a8d37f3c4318795e547a45957199c860dda923cdde86"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
